cequal0
√¥equal1
 equal2
tequal3
·∫•equal4
mequal5
,equal6
bequal7
·ªëequal8
nequal9
gequal10
aequal11
qequal12
uequal13
·∫£equal14
hequal15
·ªãequal16
∆°equal17
‚Ä¶equal18
·ªØequal19
√¨equal20
requal21
oequal22
.equal23
ƒëequal24
√£equal25
·ªüequal26
√™equal27
vequal28
√πequal29
eequal30
·ªôequal31
·ªõequal32
iequal33
·ªïequal34
·ªßequal35
·∫ªequal36
·ªáequal37
dequal38
‚Äùequal39
1equal40
5equal41
8equal42
‚Ä≥equal43
yequal44
kequal45
·ªÉequal46
·ªÅequal47
lequal48
√†equal49
·∫øequal50
·ª•equal51
√°equal52
·∫°equal53
∆∞equal54
·ª£equal55
√∫equal56
pequal57
·ª°equal58
≈©equal59
√≥equal60
sequal61
·ªçequal62
√≠equal63
√©equal64
·∫Ωequal65
·∫Øequal66
·∫∑equal67
√¢equal68
·ªùequal69
·ª±equal70
·ªìequal71
xequal72
·ª≠equal73
·∫πequal74
√≤equal75
2equal76
:equal77
‚Äúequal78
·ªÖequal79
·ª©equal80
ƒÉequal81
·ªâequal82
·∫≥equal83
·ªèequal84
·∫ßequal85
·∫´equal86
√Ωequal87
‚Äìequal88
	equal89
·ªóequal90
?equal91
·∫©equal92
·∫≠equal93
!equal94
4equal95
·ª´equal96
√µequal97
3equal98
ƒ©equal99
·∫µequal100
·ª≥equal101
·∫±equal102
√®equal103
‚Äãequal104
6equal105
9equal106
7equal107
zequal108
·ª∑equal109
¬†equal110
0equal111
-equal112
·ªπequal113
wequal114
;equal115
√∞equal116
¬≠equal117
jequal118
fequal119
üòúequal120
·ªµequal121
Ôªøequal122
Ã£equal123
ÃÄequal124
ÃÅequal125
ÃÉequal126
Ãâequal127
¬´equal128
¬ªequal129
‚Äïequal130
/equal131
‚òπequal132
¬∑equal133
"equal134
‚Äôequal135
‚Äòequal136
‚Ä≤equal137
ÔøΩequal138
<PAD>equal139
<EOS>equal140
<GO>equal141
///////////////////////////
import tensorflow as tf
import pandas as pd
from constant import DATA_PATH
from os import path
import re
from asset.number import NUMBER
from asset.letter import VN_LETTER
from asset.vowel import LiST_S_TONES
from asset.punctuation_mark import PUNCTUATION_MARK

# load data
df = pd.read_excel(path.join(DATA_PATH, 'train_spell.xlsx'), sheet_name="data train")
codes = ['<EOS>', '<GO>', '<PAD>', '<UNK>']


# create data set
def pre_processing_sentence(sentence):
    sentence = re.sub(r'([.,!?()])', r' \1 ', str(sentence))
    sentence = re.sub(r'\s{2,}', ' ', sentence)
    sentence = re.sub(r'\<|\>', '', sentence)
    sentence = codes[1] + sentence + codes[0]
    return sentence


err_sentences = list()
cor_sentences = list()
for index, row in df.iterrows():
    err_sentence = pre_processing_sentence(df.loc[index]['error sentences'])
    cor_sentence = pre_processing_sentence(df.loc[index]['correct sentences'])
    err_sentences.append(err_sentence)
    cor_sentences.append(cor_sentence)


# def tokenize(sentences):
#     sentence_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=" ")
#     sentence_tokenizer.fit_on_texts(sentences)
#     tensor = sentence_tokenizer.texts_to_sequences(sentences)
#     tensor = tf.keras.preprocessing.sequence.pad_sequences(sequences=tensor,
#                                                            padding='post')
#     return tensor, sentence_tokenizer
#
# tensor, sentence_tokenizer = tokenize(err_sentences)
# print(err_sentences[-1])
# print(tensor[-1])
#
def init_vocabulary(sentences):
    vocab_word_to_int = dict()
    vocab_int_to_word = dict()
    count = 0
    vocab_word_to_int[" "] = count

    for letter_code in codes:
        vocab_word_to_int[letter_code] = count
        count += 1
    for number in NUMBER:
        vocab_word_to_int[number] = count
        count += 1
    for letter in VN_LETTER:
        vocab_word_to_int[letter] = count
        count += 1
    for vowel in LiST_S_TONES:
        vocab_word_to_int[vowel] = count
        count += 1
    for mark in PUNCTUATION_MARK:
        vocab_word_to_int[mark] = count
        count += 1
    # for sentence in sentences:
    #     for letter in sentence:
    #         if letter not in vocab_word_to_int.keys():
    #             vocab_word_to_int[letter] = count
    #             count += 1
    vocab_word_to_int[" "] = count
    for key, value in vocab_word_to_int.items():
        vocab_int_to_word[value] = key

    return vocab_word_to_int, vocab_int_to_word


vocab_word_to_int_, vocab_int_to_word_ = init_vocabulary(sentences=err_sentences + cor_sentences)


# covert to int
def convert_sentences(sentences, vocab):
    convert_sen = list()
    for sentence in sentences:
        new_sentence = list()
        for letter in sentence:
            if letter in vocab.keys():
                new_sentence.append(vocab[letter])
            else:
                new_sentence.append(vocab['<UNK>'])
        convert_sen.append(new_sentence)
    return convert_sen


int_err_sentences = convert_sentences(err_sentences, vocab_word_to_int_)
int_cor_sentences = convert_sentences(cor_sentences, vocab_int_to_word_)
